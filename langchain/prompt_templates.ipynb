{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from langchain_core.runnables import ConfigurableField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatGroq(temperature=0.2,api_key=os.getenv('GROQ_API_KEY'),model='mixtral-8x7B-32768').configurable_fields(\n",
    "    max_tokens=ConfigurableField(\n",
    "                id=\"output_token_number\",\n",
    "                name=\"Max tokens in the output\",\n",
    "                description=\"The maximum number of tokens in the output\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = 'you are a helpful assistant'\n",
    "human = '{text}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([('system',system),('human',human)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (prompt | chat).with_config(\n",
    "    config={'output_token_number':30}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({'text':\"hello how are you\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'completion_tokens': 30, 'prompt_tokens': 19, 'total_tokens': 49, 'completion_time': 0.047346144, 'prompt_time': 0.003645439, 'queue_time': None, 'total_time': 0.050991583}\n"
     ]
    }
   ],
   "source": [
    "print(response.response_metadata['token_usage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage,SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content='you are a helpful assistant'),\n",
    "    HumanMessage(content='hi!')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! I'm here to help. How can I assist you today? If you have any questions or need information on a particular topic, feel free to ask. I'll do my best to provide accurate and relevant answers. Let's get started!\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! I'm here to help. How can I assist you today? If you have any questions or need information on a particular topic, feel free to ask. I'll do my best to provide accurate and relevant answers. Let's get started!\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.invoke(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | chat | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Neuroscience is the scientific study of the nervous system, including the brain and all of the nerves of the body. It is a multidisciplinary field that combines biology, chemistry, physics, mathematics, and engineering to understand the structure, function, development, and evolution of the nervous system.\\n\\nNeuroscientists study the nervous system at multiple levels, from the molecular and cellular level to the systems level, and use a variety of techniques and approaches to do so. These may include molecular and cellular biology, biochemistry, electrophysiology, neuroimaging, and behavioral and cognitive neuroscience.\\n\\nSome of the key areas of focus in neuroscience include understanding how the brain processes sensory information, how it generates motor behaviors, how it encodes and stores memories, and how it regulates emotions and cognition. Neuroscientists also study the neural basis of neurological and psychiatric disorders, such as Alzheimer's disease, Parkinson's disease, depression, and schizophrenia, and work to develop new treatments and therapies for these conditions.\\n\\nNeuroscience has made significant contributions to our understanding of the brain and has led to many important advances in medicine, technology, and society. It is a rapidly growing field with many exciting opportunities for research and discovery.\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'text' : 'tell me about neuroscience'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = 'You are a translator. Translate the following into {lang}. You will only return the translation and nothing else'\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [('system',system_template),('user','{text}')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = prompt_template.invoke({'lang':'spanish','text':'hello who are you?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a translator. Translate the following into spanish. You will only return the translation and nothing else'),\n",
       " HumanMessage(content='hello who are you?')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_template | chat | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = chain.invoke({'lang':'spanish','text':'hello what is your name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hola ¿cómo te llamas?'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
