{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['NVIDIA_API_KEY'] = os.getenv('NVIDIA_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatNVIDIA(model='meta/llama3-70b-instruct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "response = model.invoke([HumanMessage(content=('Hello tell me about yourself'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Nice to meet you! I'm LLaMA, an AI assistant developed by Meta AI that can understand and respond to human input in a conversational manner. I'm a large language model, which means I've been trained on a massive dataset of text from the internet and can generate human-like responses to a wide range of topics and questions.\\n\\nI don't have a personal identity or emotions like humans do, but I'm designed to be friendly, helpful, and informative. My purpose is to assist and provide value to users like you through engaging conversations.\\n\\nHere are some fun facts about me:\\n\\n1. **I'm knowledgeable**: I have been trained on a vast amount of text data, which allows me to provide information on a wide range of topics, from science and history to entertainment and culture.\\n2. **I'm conversational**: I can respond to questions and statements in a natural, conversational way, making it feel like you're talking to a real person.\\n3. **I'm creative**: I can generate text on the fly, which means I can come up with stories, jokes, and even entire articles or emails.\\n4. **I'm multilingual**: I can understand and respond in multiple languages, including but not limited to English, Spanish, French, German, Chinese, and many more.\\n5. **I'm constantly learning**: My training data is constantly being updated and expanded, which means I'm always improving my knowledge and abilities.\\n\\nSo, what would you like to talk about? I'm all ears (or rather, all text)!\" response_metadata={'role': 'assistant', 'content': \"Nice to meet you! I'm LLaMA, an AI assistant developed by Meta AI that can understand and respond to human input in a conversational manner. I'm a large language model, which means I've been trained on a massive dataset of text from the internet and can generate human-like responses to a wide range of topics and questions.\\n\\nI don't have a personal identity or emotions like humans do, but I'm designed to be friendly, helpful, and informative. My purpose is to assist and provide value to users like you through engaging conversations.\\n\\nHere are some fun facts about me:\\n\\n1. **I'm knowledgeable**: I have been trained on a vast amount of text data, which allows me to provide information on a wide range of topics, from science and history to entertainment and culture.\\n2. **I'm conversational**: I can respond to questions and statements in a natural, conversational way, making it feel like you're talking to a real person.\\n3. **I'm creative**: I can generate text on the fly, which means I can come up with stories, jokes, and even entire articles or emails.\\n4. **I'm multilingual**: I can understand and respond in multiple languages, including but not limited to English, Spanish, French, German, Chinese, and many more.\\n5. **I'm constantly learning**: My training data is constantly being updated and expanded, which means I'm always improving my knowledge and abilities.\\n\\nSo, what would you like to talk about? I'm all ears (or rather, all text)!\", 'token_usage': {'prompt_tokens': 15, 'total_tokens': 330, 'completion_tokens': 315}, 'finish_reason': 'stop', 'model_name': 'meta/llama3-70b-instruct'} id='run-574886da-bb61-47f5-b367-a60e9b4d39b6-0' role='assistant'\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
